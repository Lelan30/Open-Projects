{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhjthE0XnXRi4euXCLiZ4o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lelan30/Open-Projects/blob/main/Melanoma_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **About this Competition**\n",
        "**What should I expect the data format to be?**\n",
        "The images are provided in DICOM format. This can be accessed using commonly-available libraries like *pydicom*, and contains both image and metadata. It is a commonly used medical imaging data format.\n",
        "\n",
        "Images are also provided in JPEG and TFRecord format (in the *jpeg* and *tfrecords* directories, respectively). Images in TFRecord format have been resized to a uniform 1024x1024.\n",
        "\n",
        "Metadata is also provided outside of the DICOM format, in CSV files. See the Columns section for a description.\n",
        "\n",
        "**What am I predicting?**\n",
        "\n",
        "You are predicting a binary target for each image. Your model should predict the probability (floating point) between 0.0 and 1.0 that the lesion in the image is malignant (the target). In the training data, train.csv, the value 0 denotes benign, and 1 indicates malignant."
      ],
      "metadata": {
        "id": "MV_2-9YshpNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Files**\n",
        "*   train.csv - the training set\n",
        "*   test.csv - the test set\n",
        "*   sample_submission.csv - a sample submission file in the correct format\n",
        "\n",
        "**Columns**\n",
        "*   image_name - unique identifier, points to filename of related DICOM image\n",
        "*   patient_id - unique patient identifier\n",
        "*   sex - the sex of the patient (when unknown, will be blank)\n",
        "*   age_approx - approximate patient age at time of imaging\n",
        "*   anatom_site_general_challenge - location of imaged site\n",
        "*   diagnosis - detailed diagnosis information (train only)\n",
        "*   benign_malignant - indicator of malignancy of imaged lesion\n",
        "*   target - binarized version of the target variable"
      ],
      "metadata": {
        "id": "YakT6LGTiKh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKvUG1XWVyqk",
        "outputId": "ac405d50-6015-4862-d23b-b7d98c410835"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6EDHg2tzyPGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "608a2a18-38ce-468b-9b16-431153e3e17a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torchtoolbox in /usr/local/lib/python3.10/dist-packages (0.1.8.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtoolbox) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtoolbox) (4.65.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from torchtoolbox) (9.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtoolbox) (1.16.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (from torchtoolbox) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torchtoolbox) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torchtoolbox) (1.10.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from torchtoolbox) (4.7.0.72)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from torchtoolbox) (6.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from torchtoolbox) (2.12.2)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from torchtoolbox) (0.7.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from torchtoolbox) (4.29.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torchtoolbox) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torchtoolbox) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtoolbox) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtoolbox) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtoolbox) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtoolbox) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtoolbox) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtoolbox) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtoolbox) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtoolbox) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtoolbox) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtoolbox) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtoolbox) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtoolbox) (0.40.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet_pytorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet_pytorch) (16.0.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers->torchtoolbox) (0.14.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->torchtoolbox) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->torchtoolbox) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->torchtoolbox) (0.13.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtoolbox) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtoolbox) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtoolbox) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtoolbox) (1.3.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->torchtoolbox) (2023.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtoolbox) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtoolbox) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtoolbox) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtoolbox) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->torchtoolbox) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->torchtoolbox) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtoolbox) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install efficientnet_pytorch torchtoolbox"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torchtoolbox.transform as transforms\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import datetime\n",
        "import warnings\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "JwyigIlMzkP1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# Psudo-Random Number Generator\n",
        "def seed_everything(seed):\n",
        "  random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(47)"
      ],
      "metadata": {
        "id": "HFutwKijYiZO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "tXvxhyVlZ-5y"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MelanomaDataset(Dataset):\n",
        "  def __init__(self, df: pd.DataFrame, imfolder: str, train: bool = True,\n",
        "               transforms = None, meta_features = None):\n",
        "    '''\n",
        "    Class initiation args:\n",
        "    df (pd.DataFrame): DataFrame with data description\n",
        "    imfolder (str): folder with images\n",
        "    train (bool): flag of whether a training dataset is being initialized or testing one\n",
        "    transforms: image transformation method to be applied\n",
        "    meta_features (list): list of features with meta information, such as sex and age\n",
        "    '''\n",
        "    self.df = df\n",
        "    self.imfolder = imfolder\n",
        "    self.train = train\n",
        "    self.transforms = transforms\n",
        "    self.meta_features = meta_features\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    im_path = os.path.join(self.imfolder, \n",
        "                           self.df.iloc[index]['image_name'] + '.jpg')\n",
        "    x = cv2.imread(im_path)\n",
        "    meta = np.array(self.df.iloc[index][self.meta_features].values,\n",
        "                    dtype=np.float32)\n",
        "    if self.transforms:\n",
        "      x = self.transforms(x)\n",
        "    if self.train:\n",
        "      y = self.df.iloc[index]['target']\n",
        "      return (x, meta), y\n",
        "    else:\n",
        "      return (x, meta)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.df)\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, arch, n_meta_features: int):\n",
        "    super(Net, self).__init__()\n",
        "    self.arch = arch\n",
        "    if 'Resnet' in str(arch.__class__):\n",
        "      self.arch.fc = nn.Linear(in_features = 512,\n",
        "                                out_features= 500, \n",
        "                                bias = True)\n",
        "    if 'EfficientNet' in str(arch.__class__):\n",
        "      self.arch._fc = nn.Linear(in_features= 1280,\n",
        "                                out_features= 500, \n",
        "                                bias = True)\n",
        "      self.meta = nn.Sequential(nn.Linear(n_meta_features, 500),\n",
        "                                nn.BatchNorm1d(500),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Dropout(p= 0.2),\n",
        "                                nn.Linear(500, 250),\n",
        "                                # FC layer output will have 250 feats\n",
        "                                nn.BatchNorm1d(250),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Dropout(p = 0.2))\n",
        "      self.output = nn.Linear(500 + 250, 1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "      '''\n",
        "      No sigmoid in forward because we will be using BCEWithLogitsLoss.\n",
        "      Which applies sigmoid automatically when calculating a loss.\n",
        "      '''\n",
        "      x, meta = inputs\n",
        "      cnn_features = self.arch(x)\n",
        "      meta_features = self.meta(x)\n",
        "      features = torch.cat((cnn_features, meta_features), dim = 1)\n",
        "      output = self.output(features)\n",
        "      return output"
      ],
      "metadata": {
        "id": "hEkhewPgz3q8"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdvancedHairAugumentation:\n",
        "  '''\n",
        "  Impose image of a hair to the target image\n",
        "\n",
        "  Args:\n",
        "    hairs (int): max number of hairs to impose\n",
        "    hairs_folder (str): path to the folder with hairs images\n",
        "  '''\n",
        "\n",
        "  def __init__(self, hairs: int = 5, hairs_folder: str = \"\"):\n",
        "    self.hairs = hairs\n",
        "    self.hairs_folder = hairs_folder\n",
        "\n",
        "  def __call__(self, img):\n",
        "    '''\n",
        "    Args:\n",
        "      img (PIL Image): Image to draw hairs on.\n",
        "\n",
        "    Returns:\n",
        "      PIL Image: Image with drawn hairs.\n",
        "    '''\n",
        "    n_hairs = random.randint(0, self.hairs)\n",
        "\n",
        "    if not n_hairs:\n",
        "      return img\n",
        "    # target img width and height\n",
        "    height, weight, _ = img.shape\n",
        "    hair_images = [im for im in os.listdir(self.hairs_folder) if 'png' in im]\n",
        "\n",
        "    for _ in range(n_hairs):\n",
        "      hair = cv2.imread(os.path.join(self.hairs_folder, random.choice(hair_images)))\n",
        "      hair = cv2.flip(hair, random.choice([-1, 0, 1]))\n",
        "      hair = cv2.rotate(hair, random.choice(0, 1, 2))\n",
        "      # hair image width and height\n",
        "      h_height, h_width, _ = hair.shape\n",
        "      roi_ho = random.randint(0, img.shape[0]) - hair.shape[0]\n",
        "      roi_wo = random.randint(0, img.shape[1] - hair.shape[1])\n",
        "      roi = img[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width]\n",
        "      # creating a mask and inverse mask\n",
        "      img2gray = cv2.cvtColor(hair, cv2.COLORBGR2GRAY)\n",
        "      ret, mask = cv2.threshhold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
        "      mask_inv = cv2.bitwise_not(mask)\n",
        "      # now black-out the area of hair in ROI (background)\n",
        "      img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
        "      # take only region of hair from image\n",
        "      hair_fg = cv2.bitwise_and(hair, hair, mask=mask)\n",
        "      # put hair in ROI and modify the target img\n",
        "      dst = cv2.add(img_bg, hair_fg)\n",
        "      img[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width] = dst\n",
        "\n",
        "      return img\n",
        "\n",
        "    def __repr__(self):\n",
        "      return f'{self.__class__.__name__}(hairs={self.hairs}, hairs_folder=\"{self.hairs_folder}\")'\n"
      ],
      "metadata": {
        "id": "4ovHOymQdAyw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DrawHair:\n",
        "  '''\n",
        "  Draw a random number of psudo hairs\n",
        "\n",
        "  Args:\n",
        "    hairs (int): max number of hairs to draw\n",
        "    width (tuple): possible width of hair in poxe;s\n",
        "  '''\n",
        "  def __init__(self, hairs:int = 4, width:tuple = (1,2)):\n",
        "    self.hairs = hairs\n",
        "    self.width = width\n",
        "\n",
        "  def __call__(self, img):\n",
        "    '''\n",
        "    Args:\n",
        "      img (PIL Image): Image to draw hairs on\n",
        "\n",
        "    Returns:\n",
        "      PIL Image: Image with drawn hairs.\n",
        "    '''\n",
        "    if not self.hairs:\n",
        "      return img\n",
        "\n",
        "    width, height, _ = img.shape\n",
        "\n",
        "    for _ in range(random.randit(0,self.hairs)):\n",
        "      # The origin point of the line will always be at the top half of the image\n",
        "      origin = (random.randit(0, width), random.randit(0, height // 2))\n",
        "      # The end of the line\n",
        "      end = (random.randit(0, width), random.randit(0, height))\n",
        "      # color of the hair is Black\n",
        "      color = (0, 0, 0)\n",
        "      cv2.line(img, origin, end, color, \n",
        "               random.randit(self.width[0], self.width[1]))\n",
        "      \n",
        "    return img\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f'{self.__class__.__name__}(hairs={self.hairs}, width={self.width})'"
      ],
      "metadata": {
        "id": "mEp4zfR6LEPq"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Microscope:\n",
        "  '''\n",
        "  Cutting out the edges around the center circle of the image.\n",
        "  Imitating a picture, taken through the microscope.\n",
        "\n",
        "  Args:\n",
        "    p (float): probability of applying an augmentation\n",
        "  '''\n",
        "\n",
        "  def __init__(self, p: float = 0.5):\n",
        "    self.p = p\n",
        "\n",
        "  def __call__(self, img):\n",
        "    '''\n",
        "    Args:\n",
        "      img (PIL Image): Image to apply transformation to\n",
        "\n",
        "    Returns:\n",
        "      PIL Image: Image with transformation.\n",
        "    '''\n",
        "    if random.random() < self.p:\n",
        "      circle = cv2.circle((np.ones(img.shape) * 255).astype(np.uint8), # Image placeholder\n",
        "                          (img.shape[0]//2, img.shape[1]//2), # Center point of circle\n",
        "                          (0, 0, 0), -1) # color\n",
        "      mask = circle - 255\n",
        "      img = np.multiply(img, mask)\n",
        "\n",
        "    return img\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f'{self.__class__.__name__}(p={self.p})'"
      ],
      "metadata": {
        "id": "h5deioxyC215"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    AdvancedHairAugumentation(hairs_folder='/kaggle/input/melanoma_hairs'),\n",
        "    transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    Microscope(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.299, 0.244, 0.255])\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "U165VRFLE4eX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arch = EfficientNet.from_pretrained('efficientnet-b1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7ednRpAeKUT",
        "outputId": "8b5d6b41-a66b-4e34-929d-c86b99a3a4d2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train.csv') \n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "IDlKWE0jQUpI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding of anatom_site_general_challenge feature\n",
        "concat = pd.concat([train_df['anatom_site_general_challenge'], \n",
        "                    test_df['anatom_site_general_challenge']], \n",
        "                   ignore_index=True)\n",
        "'''\n",
        "pd.get_dummies:\n",
        "Each variable is converted in as many 0/1 variables as there are \n",
        "different values. Columns in the output are each named after a value; \n",
        "if the input is a DataFrame, the name of the original variable is \n",
        "prepended to the value.\n",
        "'''\n",
        "dummies = pd.get_dummies(concat, dummy_na=True, dtype=np.uint8, prefix='site')\n",
        "train_df = pd.concat([train_df, dummies.iloc[:train_df.shape[0]]], axis=1)\n",
        "test_df = pd.concat([test_df, dummies.iloc[:train_df.shape[0]:]\n",
        "                     .reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Sex features\n",
        "train_df['sex'] = train_df['sex'].map({'male':1, 'female':0})\n",
        "test_df['sex'] = test_df['sex'].map({'male':1, 'female':0})\n",
        "train_df['sex'] = train_df['sex'].fillna(-1)\n",
        "test_df['sex'] = test_df['sex'].fillna(-1)\n",
        "\n",
        "# Age features\n",
        "train_df['age_approx'] /= train_df['age_approx'].max()\n",
        "test_df['age_approx'] /= test_df['age_approx'].max()\n",
        "train_df['age_approx'] = train_df['age_approx'].fillna(0)\n",
        "test_df['age_approx'] = test_df['age_approx'].fillna(0)\n",
        "\n",
        "train_df['patient_id'] = train_df['patient_id'].fillna(0)"
      ],
      "metadata": {
        "id": "ZKSNYxxAQUCN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_features = ['sex', 'age_approx'] + [col for col in train_df.columns if 'site_' in col]\n",
        "meta_features.remove('anatom_site_general_challenge')"
      ],
      "metadata": {
        "id": "vfdP3GpDCCTy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = MelanomaDataset(df=test_df,\n",
        "                       imfolder='/kaggle/input/melanoma-external-malignant-256/test/test/', \n",
        "                       train=False,\n",
        "                       transforms=train_transform,  # For TTA\n",
        "                       meta_features=meta_features)"
      ],
      "metadata": {
        "id": "NZ6Y989YC0pc"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = GroupKFold(n_splits=5)"
      ],
      "metadata": {
        "id": "jp4y3cOzE0C9"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of epochs to run\n",
        "epochs = 12\n",
        "# Early stopping patience - for how many epochs with no improvements to wait\n",
        "es_patience = 3\n",
        "# Test Time Augmentation rounds\n",
        "TTA = 3\n",
        "# Out-Of-Folds predictions\n",
        "oof = np.zeros((len(train_df), 1))\n",
        "# Predictions for test set\n",
        "preds = torch.zeros((len(test), 1), dtype=torch.float32, device=device)\n",
        "\n",
        "skf = KFold(n_splits=5, shuffle=True, random_state=47)\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)),\n",
        "                                                      y=train_df['target'],\n",
        "                                                      groups=train_df['patient_id']\n",
        "                                                      .tolist()), 1):\n",
        "  print('=' * 20, 'Fold', fold, '=' * 20)\n",
        "  # Path and filename to save model to\n",
        "  model_path = f'model_{fold}.pth'\n",
        "  # Best validation score within this fold\n",
        "  best_val = 0\n",
        "  # Current patience counter\n",
        "  patience = es_patience\n",
        "  arch = EfficientNet.from_pretrained('efficientnet-b1')\n",
        "  model = Net(arch=arch, n_meta_features=len(meta_features))\n",
        "  model = model.to(device)\n",
        "\n",
        "  optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "  scheduler = ReduceLROnPlateau(optimizer=optim, \n",
        "                                mode='max', \n",
        "                                patience=1,\n",
        "                                verbose=True,\n",
        "                                factor=0.2)\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  train = MelanomaDataset(df=train_df.iloc[train_idx].reset_index(drop=True),\n",
        "                          imfolder='/kaggle/input/melanoma-external-malignant-256/train/train/',\n",
        "                          train=True,\n",
        "                          transforms=test_transform,\n",
        "                          meta_features=meta_features)\n",
        "  val = MelanomaDataset(df=train_df.iloc[val_idx].reset_index(drop=True),\n",
        "                        imfolder='/kaggle/input/melanoma-external-malignant-256/train/train/',\n",
        "                        train=True,\n",
        "                        transforms=test_transform,\n",
        "                        meta_features=meta_features)\n",
        "  train_loader = DataLoader(dataset=train, \n",
        "                            batch_size=64,\n",
        "                            shuffle=True,\n",
        "                            num_workers=2)\n",
        "  val_loader = DataLoader(dataset=test,\n",
        "                          batch_size=16,\n",
        "                          shuffle=False,\n",
        "                          num_workers=2)\n",
        "  test_loader = DataLoader(dataset=test, \n",
        "                           batch_size=16, \n",
        "                           shuffle=False, \n",
        "                           num_workers=2)\n",
        "  for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    correct = 0\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for x, y in train_loader:\n",
        "      x[0] = torch.tensor(x[0], device=device, dtype=torch.float32)\n",
        "      x[1] = torch.tensor(x[1], device=device, dtype=torch.float32)\n",
        "      y = torch.tensor(y, device=device, dtype=torch.float32)\n",
        "      optim.zero_grad()\n",
        "      z = model(x)\n",
        "      loss = criterion(z, y.unsqueeze(1))\n",
        "      optim.step()\n",
        "      # round off sigmoid to obtain predictions\n",
        "      pred = torch.round(torch.sigmoid(z))\n",
        "      # tracking number of correctly predicted samples\n",
        "      correct += (pred.cpu() == y.cpu().unsqueeze(1)).sum().item()\n",
        "      epoch_loss += loss.item()\n",
        "    train_acc = correct / len(train_idx)\n",
        "    # switch model to evaluation mode\n",
        "    model.eval()\n",
        "    val_preds = torch.zeros((len(val_idx), 1), \n",
        "                            dtype=torch.float32, \n",
        "                            device=device)\n",
        "    # Do not calculate gradient since we are only predicting\n",
        "    with torch.no_grad():\n",
        "      # predicting on validation set\n",
        "      for j, (x_val, y_val) in enumerate(val_loader):\n",
        "        x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
        "        x_val[1] = torch.tensor(x[1], device=device, dtype=torch.float32)\n",
        "        y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
        "        z_val = model(x_val)\n",
        "        val_pred = torch.sigmoid(z_val)\n",
        "        val_preds[j*val_loader.\n",
        "                  batch_size:j*val_loader.\n",
        "                  batch_size + x_val[0].shape[0]] = val_pred\n",
        "        val_acc = accuracy_score(train_df.iloc[val_idx['target'].values, \n",
        "                                torch.round(val_preds.cpu())])\n",
        "        val_roc = roc_auc_score(train_df.iloc[val_idx]['target'].values, \n",
        "                                val_preds.cpu())\n",
        "        \n",
        "        print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Val acc: {:.3f} | Val roc_auc: {:.3f} | Training time: {}'.format(\n",
        "            \n",
        "        epoch + 1,\n",
        "        epoch_loss,\n",
        "        train_acc,\n",
        "        val_acc,\n",
        "        val_roc,\n",
        "        str(datetime.timedelta(seconds=time.time() - start_time)) [:7]))\n",
        "\n",
        "        scheduler.step(val_roc)\n",
        "\n",
        "        if val_roc >= best_val:\n",
        "          best_val = val_roc\n",
        "          # Resetting patience since we have new best validation accuracy\n",
        "          patience = es_patience\n",
        "          # Saving current best model\n",
        "          torch.save(model, model_path)\n",
        "        else:\n",
        "          patience -= 1\n",
        "          if patience == 0:\n",
        "              print('Early stopping. Best Val roc_auc: {:.3f}'.format(best_val))\n",
        "              break\n",
        "  # Loading best model of this fold\n",
        "  model = torch.load(model_path)\n",
        "  # Switch model to evaluation mode\n",
        "  model.eval()\n",
        "  val_preds = torch.zeros((len(val_idx), 1), \n",
        "                          dtype=torch.float32, \n",
        "                          device=device)\n",
        "  with torch.no_grad():\n",
        "    # Predicting on validation set once again to obtain data for OOF\n",
        "    for j, (x_val, y_val) in enumerate(val_loader):\n",
        "      x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
        "      x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
        "      y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
        "      z_val = model(x_val)\n",
        "      val_pred = torch.sigmoid(z_val)\n",
        "      val_preds[j*val_loader.batch_size:j*val_loader.batch_size + x_val[0].shape[0]] = val_pred\n",
        "      oof[val_idx] = val_preds.cpu().numpy()\n",
        "\n",
        "      # Predicting on set\n",
        "      tta_preds = torch.zeros((len(test), 1), \n",
        "                              dtype=torch.float32, \n",
        "                              device=device)\n",
        "      for _ in range(TTA):\n",
        "        for i, x_test in enumerate(test_loader):\n",
        "          x_test[0] = torch.tensor(x_test[0], device=device, dtype=torch.float32)\n",
        "          x_test[1] = torch.tensor(x_test[1], device=device, dtype=torch.float32)\n",
        "          z_test = model(x_test)\n",
        "          z_test = torch.sigmoid(z_test)\n",
        "          tta_preds[i*test_loader.batch_size:i*test_loader.batch_size + x_test[0].shape[0]] += z_test\n",
        "          preds += tta_preds / TTA\n",
        "\n",
        "  preds /= skf.nsplits\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-CUNmt7sFMCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving OOF predictions so stacking would be easier\n",
        "pd.Series(oof.reshape(-1,)).to_csv('oof.csv', index=False)"
      ],
      "metadata": {
        "id": "_prwK2TS0-r5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}